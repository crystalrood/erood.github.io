<!DOCTYPE html>
<html lang="en">

<head>
      <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <meta name="description" content="Data Science for Political and Social Phenomena">
    <meta name="author" content="Chris Albon">
    <link rel="icon" href="../favicon.ico">

    <title>K-Nearest Neighbors Classification - Machine Learning</title>

    <!-- JQuery -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script>
        window.jQuery || document.write('<script src="../theme/js/jquery.min.js"><\/script>')
    </script>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="../theme/css/bootstrap.css" />
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <link rel="stylesheet" type="text/css" href="../theme/css/ie10-viewport-bug-workaround.css" />
    <!-- Custom styles for this template -->
    <link rel="stylesheet" type="text/css" href="../theme/css/style.css" />
    <link rel="stylesheet" type="text/css" href="../theme/css/notebooks.css" />
    <link href='https://fonts.googleapis.com/css?family=PT+Serif:400,700|Roboto:400,500,700' rel='stylesheet' type='text/css'>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
     <link href="http://chrisalbon.com/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Chris Albon Full RSS Feed" />        

    <meta name="tags" content="Basics" />


</head>

<body>

    <div class="navbar navbar-fixed-top">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="..">Chris Albon</a>
            </div>
            <div class="navbar-collapse collapse" id="searchbar">

                <ul class="nav navbar-nav navbar-right">
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">About<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="../pages/about.html">About Chris</a></li>
                            <li><a href="https://github.com/chrisalbon">GitHub</a></li>
                            <li><a href="https://twitter.com/chrisalbon">Twitter</a></li>
                            <li><a href="https://www.linkedin.com/in/chrisralbon">LinkedIn</a></li>
                            <li><a href="https://pinboard.in/u:chrisalbon">Pinboard</a></li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Data Science<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="..#Python">Python</a></li>
                            <li><a href="..#R_Stats">R Stats</a></li>
                            <li><a href="..#Regex">Regex</a></li>
                            <li><a href="..#Command_Line">Command Line</a></li>
                            <li><a href="..#Project_Juypter">Project Juypter</a></li>
                            <li><a href="..#SQL">SQL</a></li>
                            <li><a href="..#Mathematics">Mathematics</a></li>
                            <li><a href="..#Javascript">Javascript</a></li>
                            <li><a href="..#Probability">Probability</a></li>
                            <li><a href="..#Frequentist_Statistics">Frequentist Statistics</a></li>
                            <li><a href="..#Bayesian_Statistics">Bayesian Statistics</a></li>
                            <li><a href="..#Machine_Learning">Machine Learning</a></li>
                            <li><a href="..#GitHub">GitHub</a></li>
                            <li><a href="..#Articles">Articles</a></li>
                            <li><a href="..#Projects">Projects</a></li>
                        </ul>
                    </li>
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-haspopup="true" aria-expanded="false">Projects<span class="caret"></span></a>
                        <ul class="dropdown-menu">
                            <li><a href="http://newknowledge.io">New Knowledge</a></li>
                            <li><a href="http://partiallyderivative.com">Partially Derivative</a></li>
                            <li><a href="https://github.com/chrisalbon/Data-Science-For-Political-And-Social-Phenomena">DS4PSP</a></li>
                        </ul>
                    </li>

                    <li class="dropdown">
                        <a href="../feeds/all.rss.xml">Feed</a>
                    </li>


                </ul>

                <form class="navbar-form" action="../search.html" onsubmit="return validateForm(this.elements['q'].value);">
                    <div class="form-group" style="display:inline;">
                        <div class="input-group" style="display:table;">
                            <span class="input-group-addon" style="width:1%;"><span class="glyphicon glyphicon-search"></span></span>
                            <input class="form-control search-query" name="q" id="tipue_search_input" placeholder="e.g. scikit KNN, pandas merge" required autocomplete="off" type="text">
                        </div>
                    </div>
                </form>

            </div>
            <!--/.nav-collapse -->
        </div>
    </div>



    <!-- end of header section -->
    <div class="container">
<!-- <div class="alert alert-warning" role="alert">
    Did you find this page useful? Please do me a quick favor and <a href="#" class="alert-link">endorse me for data science on LinkedIn</a>.
</div> -->
<section id="content" class="body">
    <header>
    <h1>
      K-Nearest Neighbors Classification
    </h1>
<ol class="breadcrumb">
    <li>
        <time class="published" datetime="2016-08-31T12:00:00-07:00">
            31 August 2016
        </time>
    </li>
    <li>Machine Learning</li>
    <li>Basics</li>
</ol>
</header>
<div class='article_content'>
<p>K-nearest neighbors classifier (KNN) is a simple and powerful classification learner.</p>
<p>KNN has three basic parts:</p>
<ul>
<li><span class="math">\(y_i\)</span>: The class of an observation (what we are trying to predict in the test data).</li>
<li><span class="math">\(X_i\)</span>: The predictors/IVs/attributes of an observation.</li>
<li><span class="math">\(K\)</span>: A positive number specified by the researcher. K denotes the number of observations closest to a particular observation that define its "neighborhood". For example, K=2 means that each observation's has a neighorhood comprising of the two other observations closest to it.</li>
</ul>
<p>Imagine we have an observation where we know its independent variables <span class="math">\(x_{test}\)</span> but do not know its class <span class="math">\(y_{test}\)</span>. The KNN learner finds the K other observations that are closest to <span class="math">\(x_{test}\)</span> and uses their known classes to assign a classes to <span class="math">\(x_{test}\)</span>.</p>
<h2>Preliminaries</h2>
<div class="codehilite"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="kn">as</span> <span class="nn">pd</span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">neighbors</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>  
<span class="kn">import</span> <span class="nn">seaborn</span>
</pre></div>


<h2>Create Dataset</h2>
<p>Here we create three variables, <code>test_1</code> and <code>test_2</code> are our independent variables, 'outcome' is our dependent variable. We will use this data to train our learner.</p>
<div class="codehilite"><pre><span></span><span class="n">training_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">()</span>

<span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;test_1&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.3051</span><span class="p">,</span><span class="mf">0.4949</span><span class="p">,</span><span class="mf">0.6974</span><span class="p">,</span><span class="mf">0.3769</span><span class="p">,</span><span class="mf">0.2231</span><span class="p">,</span><span class="mf">0.341</span><span class="p">,</span><span class="mf">0.4436</span><span class="p">,</span><span class="mf">0.5897</span><span class="p">,</span><span class="mf">0.6308</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]</span>
<span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;test_2&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5846</span><span class="p">,</span><span class="mf">0.2654</span><span class="p">,</span><span class="mf">0.2615</span><span class="p">,</span><span class="mf">0.4538</span><span class="p">,</span><span class="mf">0.4615</span><span class="p">,</span><span class="mf">0.8308</span><span class="p">,</span><span class="mf">0.4962</span><span class="p">,</span><span class="mf">0.3269</span><span class="p">,</span><span class="mf">0.5346</span><span class="p">,</span><span class="mf">0.6731</span><span class="p">]</span>
<span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;outcome&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;win&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">,</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span>

<span class="n">training_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>


<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>test_1</th>
      <th>test_2</th>
      <th>outcome</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.3051</td>
      <td>0.5846</td>
      <td>win</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.4949</td>
      <td>0.2654</td>
      <td>win</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.6974</td>
      <td>0.2615</td>
      <td>win</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.3769</td>
      <td>0.4538</td>
      <td>win</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.2231</td>
      <td>0.4615</td>
      <td>win</td>
    </tr>
  </tbody>
</table>
</div>

<h2>Plot the data</h2>
<p>This is not necessary, but because we only have three variables, we can plot the training dataset. The X and Y axes are the independent variables, while the colors of the points are their classes.</p>
<div class="codehilite"><pre><span></span><span class="n">seaborn</span><span class="o">.</span><span class="n">lmplot</span><span class="p">(</span><span class="s1">&#39;test_1&#39;</span><span class="p">,</span> <span class="s1">&#39;test_2&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">training_data</span><span class="p">,</span> <span class="n">fit_reg</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span><span class="n">hue</span><span class="o">=</span><span class="s2">&quot;outcome&quot;</span><span class="p">,</span> <span class="n">scatter_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;marker&quot;</span><span class="p">:</span> <span class="s2">&quot;D&quot;</span><span class="p">,</span><span class="s2">&quot;s&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">})</span>
</pre></div>


<div class="codehilite"><pre><span></span>&lt;seaborn.axisgrid.FacetGrid at 0x11553bf98&gt;
</pre></div>


<p><img alt="png" src="../images/k-nearest_neighbors_classifer/output_9_1.png" /></p>
<h2>Convert Data Into np.arrays</h2>
<p>The <code>scikit-learn</code> library requires the data be formatted as a <code>numpy</code> array. Here are doing that reformatting.</p>
<div class="codehilite"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">training_data</span><span class="o">.</span><span class="n">as_matrix</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;test_1&#39;</span><span class="p">,</span> <span class="s1">&#39;test_2&#39;</span><span class="p">])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">training_data</span><span class="p">[</span><span class="s1">&#39;outcome&#39;</span><span class="p">])</span>
</pre></div>


<h2>Train The Learner</h2>
<p>This is our big moment. We train a KNN learner using the parameters that an observation's neighborhood is its three closest neighors. <code>weights = 'uniform'</code> can be thought of as the voting system used. For example, <code>uniform</code> means that all neighbors get an equally weighted "vote" about an observation's class while <code>weights = 'distance'</code> would tell the learner to weigh each observation's "vote" by its distance from the observation we are classifying.</p>
<div class="codehilite"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">neighbors</span><span class="o">.</span><span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">weights</span> <span class="o">=</span> <span class="s1">&#39;uniform&#39;</span><span class="p">)</span>
<span class="n">trained_model</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>


<h2>View The Model's Score</h2>
<p>How good is our trained model compared to our training data?</p>
<div class="codehilite"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>0.80000000000000004
</pre></div>


<p>Our model is 80% accurate!</p>
<p><em>Note: that in any real world example we'd want to compare the trained model to some holdout test data. But since this is a toy example I used the training data</em>.</p>
<h2>Apply The Learner To A New Data Point</h2>
<p>Now that we have trained our model, we can predict the class any new observation, <span class="math">\(y_{test}\)</span>. Let us do that now!</p>
<div class="codehilite"><pre><span></span><span class="c1"># Create a new observation with the value of the first independent variable, &#39;test_1&#39;, as .4</span>
<span class="c1"># and the second independent variable, test_1&#39;, as .6</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">.</span><span class="mi">4</span><span class="p">,</span><span class="o">.</span><span class="mi">6</span><span class="p">]])</span>
</pre></div>


<div class="codehilite"><pre><span></span><span class="c1"># Apply the learner to the new, unclassified observation.</span>
<span class="n">trained_model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>array([&#39;loss&#39;], dtype=object)
</pre></div>


<p>Huzzah! We can see that the learner has predicted that the new observation's class is <code>loss</code>.</p>
<p>We can even look at the probabilities the learner assigned to each class:</p>
<div class="codehilite"><pre><span></span><span class="n">trained_model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
</pre></div>


<div class="codehilite"><pre><span></span>array([[ 0.66666667,  0.33333333]])
</pre></div>


<p>According to this result, the model predicted that the observation was <code>loss</code> with a ~67% probability and <code>win</code> with a ~33% probability. Because the observation had a greater probability of being <code>loss</code>, it predicted that class for the observation.</p>
<h2>Notes</h2>
<ul>
<li>The choice of K has major affects on the classifer created.</li>
<li>The greater the K, more linear (high bias and low variance) the decision boundary.</li>
<li>There are a variety of ways to measure distance, two popular being simple euclidean distance and cosine similarity.</li>
</ul>
<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    var location_protocol = (false) ? 'https' : document.location.protocol;
    if (location_protocol !== 'http' && location_protocol !== 'https') location_protocol = 'https:';
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = location_protocol + '//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
</div>
    <aside>
    <div class="bug-reporting__panel">
        <h3>Find an error or bug? Have a suggestion?</h3>
        <p>Everything on this site is avaliable on GitHub. Head on over and <a href='https://github.com/chrisalbon/Data-Science-For-Political-And-Social-Phenomena/issues/new'>submit an issue.</a> You can also message me directly on <a href='https://twitter.com/chrisalbon'>Twitter</a>.</p>
    </div>
    </aside>
</section>

    </div>
    <!-- start of footer section -->
    <footer class="footer">
        <div class="container">
            <p class="text-muted">
                <center>This project contains 346 pages and is available on <a href="https://github.com/chrisalbon/Data-Science-For-Political-And-Social-Phenomena">GitHub</a>.
                <br/>
                Copyright &copy; Chris Albon,
                    <time datetime="2016">2016</time>.
                </center>
            </p>
        </div>
    </footer>

    <!-- This jQuery line finds any span that contains code highlighting classes and then selects the parent <pre> tag and adds a border. This is done as a workaround to visually distinguish the code inputs and outputs -->
    <script>
        $( ".hll, .n, .c, .err, .k, .o, .cm, .cp, .c1, .cs, .gd, .ge, .gr, .gh, .gi, .go, .gp, .gs, .gu, .gt, .kc, .kd, .kn, .kp, .kr, .kt, .m, .s, .na, .nb, .nc, .no, .nd, .ni, .ne, .nf, .nl, .nn, .nt, .nv, .ow, .w, .mf, .mh, .mi, .mo, .sb, .sc, .sd, .s2, .se, .sh, .si, .sx, .sr, .s1, .ss, .bp, .vc, .vg, .vi, .il" ).parent( "pre" ).css( "border", "1px solid #DEDEDE" );
    </script>

    <!-- Load Google Analytics -->
    <script>
        (function(i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function() {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o),
                m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

        ga('create', 'UA-66582-32', 'auto');
        ga('send', 'pageview');
    </script>
    <!-- End of Google Analytics -->

    <!-- Bootstrap core JavaScript
      ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="../theme/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../theme/js/ie10-viewport-bug-workaround.js"></script>
</body>

</html>